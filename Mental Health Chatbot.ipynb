{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f28979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "import PyPDF2\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1115588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad94b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize global variables\n",
    "chat_history = []\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "reference_vectors = {}\n",
    "model = None\n",
    "training_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41ef009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_training_data(csv_path: str = 'training_data.csv'):\n",
    "    \"\"\"Process training data from CSV with Context and Response columns.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Verify required columns exist\n",
    "        if 'Context' not in df.columns or 'Response' not in df.columns:\n",
    "            logging.error(\"Training data missing required columns 'Context' and 'Response'\")\n",
    "            return None\n",
    "            \n",
    "        # Clean the data\n",
    "        df['Context'] = df['Context'].fillna('')\n",
    "        df['Response'] = df['Response'].fillna('')\n",
    "        \n",
    "        # Combine context and response for vectorization\n",
    "        df['combined_text'] = df['Context'] + ' ' + df['Response']\n",
    "        \n",
    "        logging.info(f\"Successfully loaded {len(df)} training examples\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Training data file not found: {csv_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing training data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5307ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from PDF files.\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\\n\".join(page.extract_text() for page in reader.pages)\n",
    "            # Clean and normalize the text\n",
    "            text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "            text = ' '.join(text.split())  # Normalize whitespace\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"PDF extraction error - {pdf_path}: {str(e)}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2969f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resources():\n",
    "    \"\"\"Load and process reference materials.\"\"\"\n",
    "    global reference_vectors, training_data\n",
    "    reference_vectors.clear()\n",
    "\n",
    "    # Load specific resource files\n",
    "    resources = {\n",
    "        'Ethics Code': 'ethics-code-2017.pdf',\n",
    "        'Treatment Principles': 'principles.pdf',\n",
    "        'Ethical Foundations': 'EthicalFoundationsofPsychology.pdf'\n",
    "    }\n",
    "\n",
    "    texts = []\n",
    "    for source, file in resources.items():\n",
    "        if os.path.exists(file):\n",
    "            text = extract_pdf_text(file)\n",
    "            if text:\n",
    "                reference_vectors[source] = text\n",
    "                texts.append(text)\n",
    "                logging.info(f\"Successfully loaded: {file}\")\n",
    "        else:\n",
    "            logging.error(f\"Resource file not found: {file}\")\n",
    "\n",
    "    # Load and process training data\n",
    "    training_data = process_training_data()\n",
    "    if training_data is not None and not training_data.empty:\n",
    "        training_text = \" \".join(\n",
    "            training_data['Context'].astype(str) + \" \" + \n",
    "            training_data['Response'].astype(str)\n",
    "        )\n",
    "        training_text = ' '.join(training_text.split())  # Normalize whitespace\n",
    "        reference_vectors['Training Examples'] = training_text\n",
    "        texts.append(training_text)\n",
    "        logging.info(\"Successfully integrated training data\")\n",
    "\n",
    "    if texts:\n",
    "        vectorizer.fit(texts)\n",
    "        logging.info(\"Vectorizer fitted successfully\")\n",
    "        return True\n",
    "    else:\n",
    "        logging.error(\"No reference materials loaded\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36010efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_resource_usage(response: str) -> str:\n",
    "    \"\"\"Calculate and format resource usage.\"\"\"\n",
    "    if not isinstance(response, str):\n",
    "        logging.error(\"Response is not a string. Cannot calculate usage.\")\n",
    "        return \"Invalid response type\"\n",
    "    \n",
    "    if not reference_vectors:\n",
    "        logging.error(\"No reference materials loaded\")\n",
    "        return \"No reference materials available\"\n",
    "    \n",
    "    try:\n",
    "        response_vector = vectorizer.transform([response])\n",
    "        usage = {}\n",
    "\n",
    "        for source, text in reference_vectors.items():\n",
    "            source_vector = vectorizer.transform([text])\n",
    "            similarity = float(cosine_similarity(source_vector, response_vector)[0][0])\n",
    "            percentage = round(similarity * 100, 1)\n",
    "            if percentage > 2:  # Lower threshold to catch more subtle matches\n",
    "                usage[source] = percentage\n",
    "\n",
    "        if usage:\n",
    "            sorted_usage = sorted(usage.items(), key=lambda x: x[1], reverse=True)\n",
    "            return \"\\n\".join(f\"{source}: {pct}%\" for source, pct in sorted_usage)\n",
    "        return \"No significant resource usage detected\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Resource calculation error: {str(e)}\")\n",
    "        return \"Unable to calculate resource usage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3c87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_examples(message: str, n=2):\n",
    "    \"\"\"Find similar examples from training data for context.\"\"\"\n",
    "    if training_data is None or training_data.empty:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        message_vector = vectorizer.transform([message])\n",
    "        context_vectors = vectorizer.transform(training_data['Context'])\n",
    "        similarities = cosine_similarity(message_vector, context_vectors)[0]\n",
    "        top_indices = similarities.argsort()[-n:][::-1]\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                'context': training_data.iloc[i]['Context'],\n",
    "                'response': training_data.iloc[i]['Response'],\n",
    "                'similarity': similarities[i]\n",
    "            }\n",
    "            for i in top_indices if similarities[i] > 0.1\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error finding similar examples: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458a866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_crisis(text: str) -> bool:\n",
    "    \"\"\"Detect potential crisis situations.\"\"\"\n",
    "    crisis_keywords = {\n",
    "        'suicide', 'kill myself', 'end it all', 'want to die', 'suicidal',\n",
    "        'self harm', 'hopeless', 'worthless', 'no reason to live'\n",
    "    }\n",
    "    return any(keyword in text.lower() for keyword in crisis_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d75bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crisis_response() -> tuple:\n",
    "    \"\"\"Generate response for crisis situations.\"\"\"\n",
    "    response = \"\"\"I'm very concerned about what you're sharing and want you to know you're not alone. \n",
    "\n",
    "    Please reach out for immediate help:\n",
    "\n",
    "    • Emergency: Call 911 (US) or your local emergency number\n",
    "    • 24/7 Crisis Hotline: 988 (US)\n",
    "    • Crisis Text Line: Text HOME to 741741\n",
    "\n",
    "    Would you like help finding mental health resources in your area?\"\"\"\n",
    "\n",
    "    return response, \"Crisis Response: 100%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59178e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_response(message: str, history: list) -> tuple:\n",
    "    \"\"\"Generate chat response with resource tracking.\"\"\"\n",
    "    if not message.strip():\n",
    "        return [], \"\"\n",
    "\n",
    "    # Check for crisis\n",
    "    if detect_crisis(message):\n",
    "        response, usage = get_crisis_response()\n",
    "        history.append((message, response))\n",
    "        return history, usage\n",
    "\n",
    "    try:\n",
    "        # Find similar examples from training data\n",
    "        similar_examples = find_similar_examples(message)\n",
    "        \n",
    "        # Build prompt using history and similar examples\n",
    "        history_text = \"\\n\".join([f\"User: {h[0]}\\nAssistant: {h[1]}\" for h in history[-3:]])\n",
    "        examples_text = \"\\n\".join([\n",
    "            f\"Similar situation:\\nUser: {ex['context']}\\nResponse: {ex['response']}\"\n",
    "            for ex in similar_examples\n",
    "        ])\n",
    "\n",
    "        prompt = f\"\"\"You are a mental health support assistant. Your role is to provide empathetic, practical guidance while following these guidelines (which should not appear in your response):\n",
    "\n",
    "        Previous conversation:\n",
    "        {history_text}\n",
    "\n",
    "        Reference examples:\n",
    "        {examples_text}\n",
    "\n",
    "        User message: {message}\n",
    "\n",
    "        Respond in a natural, conversational way that:\n",
    "        - Validates and acknowledges emotions first\n",
    "        - Provides specific, evidence-based suggestions\n",
    "        - Uses warm, supportive language\n",
    "        - Includes practical coping strategies\n",
    "        - Keeps responses clear and concise\n",
    "\n",
    "        Important: Do not include these guidelines or any headers/sections in your response. Write naturally as if having a conversation.\"\"\"\n",
    "\n",
    "        model_output = model.generate_content(prompt)\n",
    "        response = model_output.text if hasattr(model_output, 'text') else str(model_output)\n",
    "        \n",
    "        usage = calculate_resource_usage(response)\n",
    "        history.append((message, response))\n",
    "        return history, usage\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Response generation error: {str(e)}\")\n",
    "        history.append((message, \"I apologize, but I'm having trouble right now. Could you rephrase your message?\"))\n",
    "        return history, \"Error calculating resource usage\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdaf39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interface():\n",
    "    \"\"\"Create and configure Gradio interface.\"\"\"\n",
    "    with gr.Blocks(css=\"\"\"\n",
    "        .chatbot { height: 70vh; overflow-y: auto }\n",
    "        .usage-box { background: #f6f6f6; padding: 10px; border-radius: 5px }\n",
    "    \"\"\") as interface:\n",
    "        gr.Markdown(\"\"\"# 🤖 Mental Health Support Assistant\"\"\")\n",
    "\n",
    "        with gr.Row():\n",
    "            chatbot = gr.Chatbot(value=[], elem_classes=\"chatbot\", bubble_full_width=True)\n",
    "            with gr.Column():\n",
    "                usage_display = gr.Textbox(label=\"Resource Usage\", elem_classes=\"usage-box\", lines=4, interactive=False)\n",
    "\n",
    "        msg = gr.Textbox(show_label=False, placeholder=\"Type your message here...\")\n",
    "        submit = gr.Button(\"Send\", variant=\"primary\")\n",
    "        clear = gr.Button(\"Clear conversation\")\n",
    "\n",
    "        gr.Markdown(\"\"\"**Disclaimer**: This AI assistant is not a substitute for professional mental health care.\"\"\")\n",
    "\n",
    "        msg.submit(chat_response, [msg, chatbot], [chatbot, usage_display], queue=False)\n",
    "        submit.click(chat_response, [msg, chatbot], [chatbot, usage_display], queue=False)\n",
    "        clear.click(lambda: ([], \"\"), None, [chatbot, usage_display], queue=False)\n",
    "\n",
    "    return interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5eb40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chatbot(api_key: str):\n",
    "    \"\"\"Initialize the chatbot.\"\"\"\n",
    "    global model\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel(\"gemini-pro\")\n",
    "        success = load_resources()\n",
    "        if not success:\n",
    "            logging.error(\"Failed to load resources\")\n",
    "            return False\n",
    "        logging.info(\"Chatbot initialized successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Initialization error: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eaae447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 18:59:22,599 - INFO - Successfully loaded: ethics-code-2017.pdf\n",
      "2025-02-17 18:59:25,157 - INFO - Successfully loaded: principles.pdf\n",
      "2025-02-17 18:59:36,350 - INFO - Successfully loaded: EthicalFoundationsofPsychology.pdf\n",
      "2025-02-17 18:59:36,498 - INFO - Successfully loaded 3512 training examples\n",
      "2025-02-17 18:59:36,819 - INFO - Successfully integrated training data\n",
      "2025-02-17 18:59:38,370 - INFO - Vectorizer fitted successfully\n",
      "2025-02-17 18:59:38,377 - INFO - Chatbot initialized successfully\n",
      "2025-02-17 18:59:38,862 - INFO - HTTP Request: GET http://127.0.0.1:7863/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-02-17 18:59:38,911 - INFO - HTTP Request: HEAD http://127.0.0.1:7863/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 18:59:42,102 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the chatbot\"\"\"\n",
    "    API_KEY = \"API_KEY\"  # Replace with your API key\n",
    "    \n",
    "    if initialize_chatbot(API_KEY):\n",
    "        interface = create_interface()\n",
    "        interface.launch(share=False)\n",
    "    else:\n",
    "        print(\"Error initializing chatbot. Please check your resources and API key.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f5447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
